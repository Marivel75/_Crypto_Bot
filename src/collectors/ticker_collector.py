"""
Service de gestion des donn√©es de tickers avec stockage hybride :
- cache m√©moire pour les donn√©es temps r√©el
- sauvegarde p√©riodique en base de donn√©es pour l'historique.
"""

import time
import threading
import uuid
from datetime import datetime, timedelta
from typing import Dict, List
from src.config.logger_settings import logger
from config.settings import config
from src.services.db_context import database_transaction
from src.models.ticker import TickerSnapshot
from src.services.exchange_factory import ExchangeFactory
from sqlalchemy import text


class TickerCache:
    """
    Cache m√©moire pour les donn√©es de tickers en temps r√©el. limite de taille pour √©viter la surcharge m√©moire.
    """

    def __init__(self, max_items_per_symbol: int = 100):
        """
        Initialise le cache des tickers.
        """
        self.cache = {}  # format du dict : {symbol: [list of ticker entries]}
        self.max_items = max_items_per_symbol
        logger.info(
            f"üìä Cache de tickers initialis√© (max {max_items_per_symbol} par symbole)"
        )

    def add_ticker(self, symbol: str, ticker_data: dict):
        """
        Ajoute un ticker au cache.
        """
        if symbol not in self.cache:
            self.cache[symbol] = []

        # Ajouter le nouveau ticker avec timestamp
        ticker_entry = {"timestamp": datetime.utcnow(), "data": ticker_data}
        self.cache[symbol].append(ticker_entry)

        # Limiter la taille du cache
        if len(self.cache[symbol]) > self.max_items:
            self.cache[symbol].pop(0)  # Supprime le plus ancien

        logger.debug(
            f"‚úÖ Ticker ajout√© pour {symbol}: {ticker_data.get('price', ticker_data.get('last', 'N/A'))} USD"
        )

    def get_recent_tickers(self, symbol: str, minutes: int = 60) -> List[dict]:
        """
        R√©cup√®re les tickers r√©cents pour un symbole.
        """
        if symbol not in self.cache:
            return []

        cutoff = datetime.utcnow() - timedelta(minutes=minutes)
        return [t for t in self.cache[symbol] if t["timestamp"] >= cutoff]

    def get_current_prices(self) -> Dict[str, dict]:
        """
        R√©cup√®re les prix actuels pour tous les symboles.
        """
        return {
            symbol: tickers[-1]["data"]
            for symbol, tickers in self.cache.items()
            if tickers
        }

    def clear_old_data(self, hours: int = 24):
        """
        Nettoie les donn√©es plus anciennes que le seuil.
        """
        cutoff = datetime.utcnow() - timedelta(hours=hours)

        for symbol in self.cache:
            # Filtrer les tickers r√©cents
            recent = [t for t in self.cache[symbol] if t["timestamp"] >= cutoff]
            self.cache[symbol] = recent

        logger.info(f"Cache nettoy√©: conservation des {hours}h pr√©c√©dentes")


class TickerCollector:
    """
    Service de collecte et stockage hybride des donn√©es de tickers :
    - cache m√©moire pour les donn√©es temps r√©el
    - sauvegarde p√©riodique en base de donn√©es pour l'historique.
    """

    def __init__(
        self,
        pairs: List[str],
        exchange: str = "binance",
        snapshot_interval: int = None,
        cache_size: int = None,
        cache_cleanup_interval: int = None,
    ):

        self.pairs = pairs
        self.exchange = exchange.lower()

        # Utiliser la configuration centralis√©e ou les valeurs par d√©faut
        self.snapshot_interval = (
            snapshot_interval
            if snapshot_interval is not None
            else config.get("ticker.snapshot_interval", 5)
        )
        self.cache_cleanup_interval = (
            cache_cleanup_interval
            if cache_cleanup_interval is not None
            else config.get("ticker.cache_cleanup_interval", 30)
        )
        cache_size = (
            cache_size
            if cache_size is not None
            else config.get("ticker.cache_size", 100)
        )

        # Initialisation du client d'API en fonction de l'exchange
        self.client = ExchangeFactory.create_exchange(exchange)

        # Initialiser le cache
        self.cache = TickerCache(max_items_per_symbol=cache_size)

        # Thread pour la collecte p√©riodique
        self.collector_thread = None
        self.running = False

        logger.info(f"TickerCollector initialis√© pour {exchange} - {len(pairs)} paires")
        logger.info(
            f"   Nettoyage du cache toutes les {self.cache_cleanup_interval} minutes"
        )

    def start_collection(self):
        """
        D√©marre la collecte p√©riodique des tickers.
        """
        if self.running:
            logger.warning("‚ö†Ô∏è  La collecte est d√©j√† en cours")
            return

        self.running = True
        self.collector_thread = threading.Thread(
            target=self._collection_loop, daemon=True, name="TickerCollector"
        )
        self.collector_thread.start()
        logger.info("Collecte des tickers d√©marr√©e")

    def stop_collection(self):
        """
        Arr√™te la collecte p√©riodique.
        """
        self.running = False
        if self.collector_thread and self.collector_thread.is_alive():
            self.collector_thread.join(timeout=5)
        self.collector_thread = None
        logger.info("Collecte des tickers arr√™t√©e")

    def _collection_loop(self):
        """
        Boucle principale de collecte des tickers.
        """
        next_snapshot = datetime.utcnow() + timedelta(minutes=self.snapshot_interval)

        while self.running:
            try:
                # 1. R√©cup√©rer les tickers
                self._fetch_and_cache_tickers()

                # 2. Sauvegarder un snapshot si n√©cessaire
                if datetime.utcnow() >= next_snapshot:
                    self._save_snapshot()
                    next_snapshot = datetime.utcnow() + timedelta(
                        minutes=self.snapshot_interval
                    )

                # 3. Nettoyer le cache r√©guli√®rement
                if datetime.utcnow().minute % self.cache_cleanup_interval == 0:
                    self.cache.clear_old_data(hours=24)

                # Attendre 1 minute
                time.sleep(60)

            except Exception as e:
                logger.error(f"‚ùå Erreur dans la collecte des tickers: {e}")
                time.sleep(10)  # Attendre avant de r√©essayer

    def _normalize_ticker_data(self, ticker_data: dict) -> dict:
        """
        Normalise les donn√©es de ticker selon l'exchange.
        """
        normalized = ticker_data.copy()

        # Normalisation selon l'exchange
        if self.exchange == "binance":
            # Binance utilise 'last' au lieu de 'price'
            if "last" in normalized and "price" not in normalized:
                normalized["price"] = normalized["last"]

            # Mapping des champs sp√©cifiques √† Binance
            if "quoteVolume" in normalized and "volume_24h" not in normalized:
                normalized["volume_24h"] = normalized["quoteVolume"]

            if "percentage" in normalized and "price_change_pct_24h" not in normalized:
                normalized["price_change_pct_24h"] = normalized["percentage"]

        elif self.exchange == "kraken":
            # Kraken a sa propre structure
            if "c" in normalized and "price" not in normalized:
                normalized["price"] = normalized["c"][0]  # Dernier prix

        elif self.exchange == "coinbase":
            # Coinbase utilise 'price' directement
            pass

        return normalized

    def _fetch_and_cache_tickers(self):
        """
        R√©cup√®re les tickers depuis l'exchange et les ajoute au cache.
        """
        for pair in self.pairs:
            try:
                ticker = self.client.fetch_ticker(pair)
                if ticker:
                    # Normaliser les donn√©es avant de les ajouter au cache
                    normalized_ticker = self._normalize_ticker_data(ticker)
                    self.cache.add_ticker(pair, normalized_ticker)
            except Exception as e:
                logger.error(f"‚ùå √âchec r√©cup√©ration ticker {pair}: {e}")

    def _save_snapshot(self):
        """
        Sauvegarde un snapshot des tickers actuels en base de donn√©es.
        Utilise des context managers pour la gestion des ressources.
        """
        try:
            current_prices = self.cache.get_current_prices()

            if not current_prices:
                logger.warning("‚ö†Ô∏è  Aucun ticker √† sauvegarder")
                return

            # Pr√©parer les snapshots pour la base de donn√©es
            snapshots = []
            for symbol, ticker_data in current_prices.items():
                snapshot = TickerSnapshot(
                    id=str(uuid.uuid4()),
                    snapshot_time=datetime.utcnow(),
                    symbol=symbol,
                    exchange=self.exchange,
                    price=ticker_data.get("price"),
                    volume_24h=ticker_data.get("volume_24h"),
                    price_change_24h=ticker_data.get("price_change_24h"),
                    price_change_pct_24h=ticker_data.get("price_change_pct_24h"),
                    high_24h=ticker_data.get("high_24h"),
                    low_24h=ticker_data.get("low_24h"),
                )
                snapshots.append(snapshot)

            # Utiliser un context manager pour la base de donn√©es
            with database_transaction() as db_conn:
                for snapshot in snapshots:
                    db_conn.execute(
                        text(
                            """
                            INSERT INTO ticker_snapshots (id, snapshot_time, symbol, exchange, price, volume_24h, 
                            price_change_24h, price_change_pct_24h, high_24h, low_24h)
                            VALUES (:id, :snapshot_time, :symbol, :exchange, :price, :volume_24h, 
                            :price_change_24h, :price_change_pct_24h, :high_24h, :low_24h)
                            """
                        ),
                        {
                            "id": snapshot.id,
                            "snapshot_time": snapshot.snapshot_time,
                            "symbol": snapshot.symbol,
                            "exchange": snapshot.exchange,
                            "price": snapshot.price,
                            "volume_24h": snapshot.volume_24h,
                            "price_change_24h": snapshot.price_change_24h,
                            "price_change_pct_24h": snapshot.price_change_pct_24h,
                            "high_24h": snapshot.high_24h,
                            "low_24h": snapshot.low_24h,
                        },
                    )

            logger.info(f"Snapshot sauvegard√©: {len(snapshots)} tickers")

        except Exception as e:
            logger.error(f"‚ùå √âchec sauvegarde snapshot: {e}")

    def get_current_prices(self) -> Dict[str, dict]:
        """
        R√©cup√®re les prix actuels depuis le cache.
        """
        return self.cache.get_current_prices()

    def get_historical_snapshots(self, symbol: str, hours: int = 24) -> List[dict]:
        """
        R√©cup√®re l'historique des snapshots depuis la base de donn√©es.
        """
        try:
            cutoff = datetime.utcnow() - timedelta(hours=hours)
            engine = get_db_engine()

            with engine.connect() as connection:
                from sqlalchemy import text

                result = connection.execute(
                    text(
                        """
                        SELECT * FROM ticker_snapshots
                        WHERE symbol = :symbol AND snapshot_time >= :cutoff
                        ORDER BY snapshot_time DESC
                    """
                    ),
                    {"symbol": symbol, "cutoff": cutoff},
                )
                return [dict(row) for row in result]
        except Exception as e:
            logger.error(f"‚ùå √âchec r√©cup√©ration historique: {e}")
            return []


# Exemple d'utilisation
if __name__ == "__main__":
    # Initialiser le collecteur
    collector = TickerCollector(
        pairs=["BTC/USDT", "ETH/USDT", "SOL/USDT"],
        exchange="binance",
        snapshot_interval=5,  # Sauvegarde toutes les 5 minutes
        cache_size=100,  # 100 tickers max par symbole en cache
    )

    # D√©marrer la collecte
    collector.start_collection()

    # Exemple: R√©cup√©rer les prix actuels
    try:
        while True:
            time.sleep(10)
            prices = collector.get_current_prices()
            if prices:
                logger.info(f"Prix actuels: {prices}")
    except KeyboardInterrupt:
        collector.stop_collection()
